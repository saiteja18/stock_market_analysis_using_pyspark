{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFPQVGIXnRDl",
        "outputId": "194250d8-c9dd-4b49-ed3e-a2f1f285e539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=ebc0edcdb6a3b1ac0be7871ba5b86a1e43dbabc13411a5216da1fbca4b3e2a91\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2bWS-yrq-WO"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initiating Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"StockAnalysis\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "df = spark.read.csv('/content/drive/MyDrive/Colab Notebooks/stock_analysis_one.csv/Stock_analysis_modified.csv', header=True, inferSchema=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIsnZbBmrs1n",
        "outputId": "9d3a43bb-438d-4c7e-aa9e-606cb176f64d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----------+------------------+------------------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+\n",
            "|Ticker|      Date|              Open|              High|               Low|             Close|         Adj Close| Volume|Month|Day|Year|         YearlHigh|         YearlyLow|Week|          WeekHigh|           WeekLow|\n",
            "+------+----------+------------------+------------------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+\n",
            "|     A|2024-05-01|136.72000122070312|138.52999877929688| 136.1300048828125| 137.9199981689453| 137.9199981689453| 324723|    5|  1|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|\n",
            "|     A|2024-04-30|138.60000610351562|139.64999389648438|136.97000122070312| 137.0399932861328| 137.0399932861328|1087300|    4| 30|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|\n",
            "|     A|2024-04-29|138.25999450683594| 139.8699951171875| 137.8800048828125|139.58999633789062|139.58999633789062| 781200|    4| 29|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|\n",
            "|     A|2024-04-26| 136.4499969482422|138.36000061035156|             135.0|137.74000549316406|137.74000549316406| 754900|    4| 26|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|\n",
            "|     A|2024-04-25|137.05999755859375| 137.2100067138672| 134.1199951171875| 136.3699951171875| 136.3699951171875| 940800|    4| 25|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|\n",
            "|     A|2024-04-24|138.33999633789062|139.88999938964844| 136.2100067138672|137.49000549316406|137.49000549316406|1553200|    4| 24|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|\n",
            "|     A|2024-04-23|137.97999572753906|139.64999389648438|136.00999450683594| 139.1999969482422| 139.1999969482422|1979400|    4| 23|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|\n",
            "|     A|2024-04-22| 133.5399932861328|135.02000427246094|131.77999877929688|133.91000366210938|133.91000366210938| 850500|    4| 22|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|\n",
            "|     A|2024-04-19|133.05999755859375|133.74000549316406|132.14999389648438|132.72999572753906|132.72999572753906|1303400|    4| 19|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|\n",
            "|     A|2024-04-18|131.25999450683594|134.44000244140625|128.33999633789062|132.44000244140625|132.44000244140625|1936600|    4| 18|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|\n",
            "|     A|2024-04-17|137.24000549316406| 137.4600067138672| 132.8699951171875| 134.5500030517578| 134.5500030517578|2084100|    4| 17|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|\n",
            "|     A|2024-04-16|140.27999877929688|140.36000061035156| 136.6300048828125| 136.8000030517578| 136.8000030517578|1345700|    4| 16|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|\n",
            "|     A|2024-04-15|142.30999755859375|            143.25|139.02000427246094|140.22000122070312|140.22000122070312|1506000|    4| 15|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|\n",
            "|     A|2024-04-12|143.58999633789062|144.66000366210938|140.25999450683594|140.72999572753906|140.72999572753906|1124500|    4| 12|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|\n",
            "|     A|2024-04-11|145.64999389648438|145.86000061035156| 143.6699981689453|             145.0|             145.0| 720100|    4| 11|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|\n",
            "|     A|2024-04-10| 144.4199981689453|145.05999755859375| 143.5500030517578|144.16000366210938|144.16000366210938|1051800|    4| 10|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|\n",
            "|     A|2024-04-09|             146.0|147.42999267578125|             145.5|147.39999389648438|147.39999389648438| 873700|    4|  9|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|\n",
            "|     A|2024-04-08| 143.8000030517578| 145.7899932861328|143.00999450683594| 144.4600067138672| 144.4600067138672|1247300|    4|  8|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|\n",
            "|     A|2024-04-05|144.17999267578125|             145.5|143.42999267578125| 144.1199951171875| 144.1199951171875|1655800|    4|  5|2024|149.63999938964844|128.02000427246094|  14|146.17999267578125|143.77000427246094|\n",
            "|     A|2024-04-04| 145.1199951171875|145.25999450683594| 141.1300048828125|141.33999633789062|141.33999633789062|1183900|    4|  4|2024|149.63999938964844|128.02000427246094|  14|146.17999267578125|143.77000427246094|\n",
            "+------+----------+------------------+------------------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42TfABpSsMdt",
        "outputId": "a37358fe-1b73-4daf-93a2-8666044e70f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('Ticker', 'string'),\n",
              " ('Date', 'date'),\n",
              " ('Open', 'double'),\n",
              " ('High', 'double'),\n",
              " ('Low', 'double'),\n",
              " ('Close', 'double'),\n",
              " ('Adj Close', 'double'),\n",
              " ('Volume', 'bigint'),\n",
              " ('Month', 'int'),\n",
              " ('Day', 'int'),\n",
              " ('Year', 'int'),\n",
              " ('YearlHigh', 'double'),\n",
              " ('YearlyLow', 'double'),\n",
              " ('Week', 'int'),\n",
              " ('WeekHigh', 'double'),\n",
              " ('WeekLow', 'double')]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7K7BWlBuGv_"
      },
      "source": [
        "##**Data Pre-Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wE9bZjAscQ8",
        "outputId": "92273390-eca9-4014-ac56-11128c24e556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------------+------------------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+--------+\n",
            "|Ticker|              Open|              High|               Low|             Close|         Adj Close| Volume|Month|Day|Year|         YearlHigh|         YearlyLow|Week|          WeekHigh|           WeekLow|TickerId|\n",
            "+------+------------------+------------------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+--------+\n",
            "|     A|136.72000122070312|138.52999877929688| 136.1300048828125| 137.9199981689453| 137.9199981689453| 324723|    5|  1|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|       A|\n",
            "|     A|138.60000610351562|139.64999389648438|136.97000122070312| 137.0399932861328| 137.0399932861328|1087300|    4| 30|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|       A|\n",
            "|     A|138.25999450683594| 139.8699951171875| 137.8800048828125|139.58999633789062|139.58999633789062| 781200|    4| 29|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|       A|\n",
            "|     A| 136.4499969482422|138.36000061035156|             135.0|137.74000549316406|137.74000549316406| 754900|    4| 26|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|\n",
            "|     A|137.05999755859375| 137.2100067138672| 134.1199951171875| 136.3699951171875| 136.3699951171875| 940800|    4| 25|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|\n",
            "|     A|138.33999633789062|139.88999938964844| 136.2100067138672|137.49000549316406|137.49000549316406|1553200|    4| 24|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|\n",
            "|     A|137.97999572753906|139.64999389648438|136.00999450683594| 139.1999969482422| 139.1999969482422|1979400|    4| 23|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|\n",
            "|     A| 133.5399932861328|135.02000427246094|131.77999877929688|133.91000366210938|133.91000366210938| 850500|    4| 22|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|\n",
            "|     A|133.05999755859375|133.74000549316406|132.14999389648438|132.72999572753906|132.72999572753906|1303400|    4| 19|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|\n",
            "|     A|131.25999450683594|134.44000244140625|128.33999633789062|132.44000244140625|132.44000244140625|1936600|    4| 18|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|\n",
            "|     A|137.24000549316406| 137.4600067138672| 132.8699951171875| 134.5500030517578| 134.5500030517578|2084100|    4| 17|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|\n",
            "|     A|140.27999877929688|140.36000061035156| 136.6300048828125| 136.8000030517578| 136.8000030517578|1345700|    4| 16|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|\n",
            "|     A|142.30999755859375|            143.25|139.02000427246094|140.22000122070312|140.22000122070312|1506000|    4| 15|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|\n",
            "|     A|143.58999633789062|144.66000366210938|140.25999450683594|140.72999572753906|140.72999572753906|1124500|    4| 12|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A|\n",
            "|     A|145.64999389648438|145.86000061035156| 143.6699981689453|             145.0|             145.0| 720100|    4| 11|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A|\n",
            "|     A| 144.4199981689453|145.05999755859375| 143.5500030517578|144.16000366210938|144.16000366210938|1051800|    4| 10|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A|\n",
            "|     A|             146.0|147.42999267578125|             145.5|147.39999389648438|147.39999389648438| 873700|    4|  9|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A|\n",
            "|     A| 143.8000030517578| 145.7899932861328|143.00999450683594| 144.4600067138672| 144.4600067138672|1247300|    4|  8|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A|\n",
            "|     A|144.17999267578125|             145.5|143.42999267578125| 144.1199951171875| 144.1199951171875|1655800|    4|  5|2024|149.63999938964844|128.02000427246094|  14|146.17999267578125|143.77000427246094|       A|\n",
            "|     A| 145.1199951171875|145.25999450683594| 141.1300048828125|141.33999633789062|141.33999633789062|1183900|    4|  4|2024|149.63999938964844|128.02000427246094|  14|146.17999267578125|143.77000427246094|       A|\n",
            "+------+------------------+------------------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, year, month, dayofmonth\n",
        "\n",
        "# Convert Ticker to unique identifier code\n",
        "df = df.withColumn(\"TickerId\", col(\"Ticker\").cast(\"string\"))\n",
        "\n",
        "# Extract year, month, and day from Date and convert to int\n",
        "df = df.withColumn(\"Year\", year(\"Date\")) \\\n",
        "       .withColumn(\"Month\", month(\"Date\")) \\\n",
        "       .withColumn(\"Day\", dayofmonth(\"Date\")) \\\n",
        "       .drop(\"Date\")\n",
        "\n",
        "# Display the updated DataFrame\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2KXkts1u4mW",
        "outputId": "866f4d58-46e8-4e2f-9b98-b8c699d3fd8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+--------+------------------+--------+\n",
            "|Ticker|              Open|              High|               Low| Volume|Month|Day|Year|         YearlHigh|         YearlyLow|Week|          WeekHigh|           WeekLow|TickerId|           Balance|In_or_de|\n",
            "+------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+--------+------------------+--------+\n",
            "|     A|136.72000122070312|138.52999877929688| 136.1300048828125| 324723|    5|  1|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|       A|1.1999969482421875|       1|\n",
            "|     A|138.60000610351562|139.64999389648438|136.97000122070312|1087300|    4| 30|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|       A|1.5600128173828125|       0|\n",
            "|     A|138.25999450683594| 139.8699951171875| 137.8800048828125| 781200|    4| 29|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|       A|1.3300018310546875|       1|\n",
            "|     A| 136.4499969482422|138.36000061035156|             135.0| 754900|    4| 26|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A| 1.290008544921875|       1|\n",
            "|     A|137.05999755859375| 137.2100067138672| 134.1199951171875| 940800|    4| 25|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|  0.69000244140625|       0|\n",
            "|     A|138.33999633789062|139.88999938964844| 136.2100067138672|1553200|    4| 24|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|0.8499908447265625|       0|\n",
            "|     A|137.97999572753906|139.64999389648438|136.00999450683594|1979400|    4| 23|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A| 1.220001220703125|       1|\n",
            "|     A| 133.5399932861328|135.02000427246094|131.77999877929688| 850500|    4| 22|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|0.3700103759765625|       1|\n",
            "|     A|133.05999755859375|133.74000549316406|132.14999389648438|1303400|    4| 19|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|0.3300018310546875|       0|\n",
            "|     A|131.25999450683594|134.44000244140625|128.33999633789062|1936600|    4| 18|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|1.1800079345703125|       1|\n",
            "|     A|137.24000549316406| 137.4600067138672| 132.8699951171875|2084100|    4| 17|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|  2.69000244140625|       0|\n",
            "|     A|140.27999877929688|140.36000061035156| 136.6300048828125|1345700|    4| 16|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|3.4799957275390625|       0|\n",
            "|     A|142.30999755859375|            143.25|139.02000427246094|1506000|    4| 15|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A| 2.089996337890625|       0|\n",
            "|     A|143.58999633789062|144.66000366210938|140.25999450683594|1124500|    4| 12|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A|2.8600006103515625|       0|\n",
            "|     A|145.64999389648438|145.86000061035156| 143.6699981689453| 720100|    4| 11|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A| 0.649993896484375|       0|\n",
            "|     A| 144.4199981689453|145.05999755859375| 143.5500030517578|1051800|    4| 10|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A|0.2599945068359375|       0|\n",
            "|     A|             146.0|147.42999267578125|             145.5| 873700|    4|  9|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A| 1.399993896484375|       1|\n",
            "|     A| 143.8000030517578| 145.7899932861328|143.00999450683594|1247300|    4|  8|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A| 0.660003662109375|       1|\n",
            "|     A|144.17999267578125|             145.5|143.42999267578125|1655800|    4|  5|2024|149.63999938964844|128.02000427246094|  14|146.17999267578125|143.77000427246094|       A|  0.05999755859375|       0|\n",
            "|     A| 145.1199951171875|145.25999450683594| 141.1300048828125|1183900|    4|  4|2024|149.63999938964844|128.02000427246094|  14|146.17999267578125|143.77000427246094|       A| 3.779998779296875|       0|\n",
            "+------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+--------+------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Drop the 'Close' and 'Adj Close' features\n",
        "df = df.drop(\"Close\", \"Adj Close\")\n",
        "\n",
        "# Display the updated DataFrame\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRoRh8J_uzfH"
      },
      "source": [
        "##**Feature Engineering**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qg1Ovx-xuSdx",
        "outputId": "1efd71e7-fed7-4d9f-e725-06dc6a31a10c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------------+------------------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+--------+------------------+--------+\n",
            "|Ticker|              Open|              High|               Low|             Close|         Adj Close| Volume|Month|Day|Year|         YearlHigh|         YearlyLow|Week|          WeekHigh|           WeekLow|TickerId|           Balance|In_or_de|\n",
            "+------+------------------+------------------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+--------+------------------+--------+\n",
            "|     A|136.72000122070312|138.52999877929688| 136.1300048828125| 137.9199981689453| 137.9199981689453| 324723|    5|  1|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|       A|1.1999969482421875|       1|\n",
            "|     A|138.60000610351562|139.64999389648438|136.97000122070312| 137.0399932861328| 137.0399932861328|1087300|    4| 30|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|       A|1.5600128173828125|       0|\n",
            "|     A|138.25999450683594| 139.8699951171875| 137.8800048828125|139.58999633789062|139.58999633789062| 781200|    4| 29|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|       A|1.3300018310546875|       1|\n",
            "|     A| 136.4499969482422|138.36000061035156|             135.0|137.74000549316406|137.74000549316406| 754900|    4| 26|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A| 1.290008544921875|       1|\n",
            "|     A|137.05999755859375| 137.2100067138672| 134.1199951171875| 136.3699951171875| 136.3699951171875| 940800|    4| 25|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|  0.69000244140625|       0|\n",
            "|     A|138.33999633789062|139.88999938964844| 136.2100067138672|137.49000549316406|137.49000549316406|1553200|    4| 24|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|0.8499908447265625|       0|\n",
            "|     A|137.97999572753906|139.64999389648438|136.00999450683594| 139.1999969482422| 139.1999969482422|1979400|    4| 23|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A| 1.220001220703125|       1|\n",
            "|     A| 133.5399932861328|135.02000427246094|131.77999877929688|133.91000366210938|133.91000366210938| 850500|    4| 22|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|0.3700103759765625|       1|\n",
            "|     A|133.05999755859375|133.74000549316406|132.14999389648438|132.72999572753906|132.72999572753906|1303400|    4| 19|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|0.3300018310546875|       0|\n",
            "|     A|131.25999450683594|134.44000244140625|128.33999633789062|132.44000244140625|132.44000244140625|1936600|    4| 18|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|1.1800079345703125|       1|\n",
            "|     A|137.24000549316406| 137.4600067138672| 132.8699951171875| 134.5500030517578| 134.5500030517578|2084100|    4| 17|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|  2.69000244140625|       0|\n",
            "|     A|140.27999877929688|140.36000061035156| 136.6300048828125| 136.8000030517578| 136.8000030517578|1345700|    4| 16|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|3.4799957275390625|       0|\n",
            "|     A|142.30999755859375|            143.25|139.02000427246094|140.22000122070312|140.22000122070312|1506000|    4| 15|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A| 2.089996337890625|       0|\n",
            "|     A|143.58999633789062|144.66000366210938|140.25999450683594|140.72999572753906|140.72999572753906|1124500|    4| 12|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A|2.8600006103515625|       0|\n",
            "|     A|145.64999389648438|145.86000061035156| 143.6699981689453|             145.0|             145.0| 720100|    4| 11|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A| 0.649993896484375|       0|\n",
            "|     A| 144.4199981689453|145.05999755859375| 143.5500030517578|144.16000366210938|144.16000366210938|1051800|    4| 10|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A|0.2599945068359375|       0|\n",
            "|     A|             146.0|147.42999267578125|             145.5|147.39999389648438|147.39999389648438| 873700|    4|  9|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A| 1.399993896484375|       1|\n",
            "|     A| 143.8000030517578| 145.7899932861328|143.00999450683594| 144.4600067138672| 144.4600067138672|1247300|    4|  8|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A| 0.660003662109375|       1|\n",
            "|     A|144.17999267578125|             145.5|143.42999267578125| 144.1199951171875| 144.1199951171875|1655800|    4|  5|2024|149.63999938964844|128.02000427246094|  14|146.17999267578125|143.77000427246094|       A|  0.05999755859375|       0|\n",
            "|     A| 145.1199951171875|145.25999450683594| 141.1300048828125|141.33999633789062|141.33999633789062|1183900|    4|  4|2024|149.63999938964844|128.02000427246094|  14|146.17999267578125|143.77000427246094|       A| 3.779998779296875|       0|\n",
            "+------+------------------+------------------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+--------+------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when, abs\n",
        "\n",
        "# Calculate the balance\n",
        "df = df.withColumn(\"Balance\", col(\"Adj Close\") - col(\"Open\"))\n",
        "\n",
        "# Mark positive balance as 1 and negative balance as 0\n",
        "df = df.withColumn(\"In_or_de\", when(col(\"Balance\") >= 0, 1).otherwise(0))\n",
        "\n",
        "# Take the absolute value of balance\n",
        "df = df.withColumn(\"Balance\", abs(col(\"Balance\")))\n",
        "\n",
        "# Display the updated DataFrame\n",
        "df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzZ0VluowVtQ",
        "outputId": "0d1f61f4-73b3-45c8-b634-f198a7f52ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+--------+------------------+--------+\n",
            "|Ticker|              Open|              High|               Low| Volume|Month|Day|Year|         YearlHigh|         YearlyLow|Week|          WeekHigh|           WeekLow|TickerId|           Balance|In_or_de|\n",
            "+------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+--------+------------------+--------+\n",
            "|     A|136.72000122070312|138.52999877929688| 136.1300048828125| 324723|    5|  1|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|       A|1.1999969482421875|       1|\n",
            "|     A|138.60000610351562|139.64999389648438|136.97000122070312|1087300|    4| 30|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|       A|1.5600128173828125|       0|\n",
            "|     A|138.25999450683594| 139.8699951171875| 137.8800048828125| 781200|    4| 29|2024|149.63999938964844|128.02000427246094|  18|138.60000610351562|136.72000122070312|       A|1.3300018310546875|       1|\n",
            "|     A| 136.4499969482422|138.36000061035156|             135.0| 754900|    4| 26|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A| 1.290008544921875|       1|\n",
            "|     A|137.05999755859375| 137.2100067138672| 134.1199951171875| 940800|    4| 25|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|  0.69000244140625|       0|\n",
            "|     A|138.33999633789062|139.88999938964844| 136.2100067138672|1553200|    4| 24|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|0.8499908447265625|       0|\n",
            "|     A|137.97999572753906|139.64999389648438|136.00999450683594|1979400|    4| 23|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A| 1.220001220703125|       1|\n",
            "|     A| 133.5399932861328|135.02000427246094|131.77999877929688| 850500|    4| 22|2024|149.63999938964844|128.02000427246094|  17|138.33999633789062| 133.5399932861328|       A|0.3700103759765625|       1|\n",
            "|     A|133.05999755859375|133.74000549316406|132.14999389648438|1303400|    4| 19|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|0.3300018310546875|       0|\n",
            "|     A|131.25999450683594|134.44000244140625|128.33999633789062|1936600|    4| 18|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|1.1800079345703125|       1|\n",
            "|     A|137.24000549316406| 137.4600067138672| 132.8699951171875|2084100|    4| 17|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|  2.69000244140625|       0|\n",
            "|     A|140.27999877929688|140.36000061035156| 136.6300048828125|1345700|    4| 16|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A|3.4799957275390625|       0|\n",
            "|     A|142.30999755859375|            143.25|139.02000427246094|1506000|    4| 15|2024|149.63999938964844|128.02000427246094|  16|142.30999755859375|131.25999450683594|       A| 2.089996337890625|       0|\n",
            "|     A|143.58999633789062|144.66000366210938|140.25999450683594|1124500|    4| 12|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A|2.8600006103515625|       0|\n",
            "|     A|145.64999389648438|145.86000061035156| 143.6699981689453| 720100|    4| 11|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A| 0.649993896484375|       0|\n",
            "|     A| 144.4199981689453|145.05999755859375| 143.5500030517578|1051800|    4| 10|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A|0.2599945068359375|       0|\n",
            "|     A|             146.0|147.42999267578125|             145.5| 873700|    4|  9|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A| 1.399993896484375|       1|\n",
            "|     A| 143.8000030517578| 145.7899932861328|143.00999450683594|1247300|    4|  8|2024|149.63999938964844|128.02000427246094|  15|             146.0|143.58999633789062|       A| 0.660003662109375|       1|\n",
            "|     A|144.17999267578125|             145.5|143.42999267578125|1655800|    4|  5|2024|149.63999938964844|128.02000427246094|  14|146.17999267578125|143.77000427246094|       A|  0.05999755859375|       0|\n",
            "|     A| 145.1199951171875|145.25999450683594| 141.1300048828125|1183900|    4|  4|2024|149.63999938964844|128.02000427246094|  14|146.17999267578125|143.77000427246094|       A| 3.779998779296875|       0|\n",
            "+------+------------------+------------------+------------------+-------+-----+---+----+------------------+------------------+----+------------------+------------------+--------+------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WYIyu2Yw8ag",
        "outputId": "6a151b65-f497-458f-96a0-1ea83a633aea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-------+\n",
            "|In_or_de|  count|\n",
            "+--------+-------+\n",
            "|       1|1744031|\n",
            "|       0|5650101|\n",
            "+--------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Count occurrences of each value in the 'In_or_de' column\n",
        "count_df = df.groupBy(\"In_or_de\").count()\n",
        "\n",
        "# Display the count DataFrame\n",
        "count_df.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOKRJKPa5Cr9"
      },
      "source": [
        "#**Working on a Sub Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW5FwRddyxhR"
      },
      "source": [
        "##**Train-Test Split on a Sub sample**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9hpWyRtvGpV",
        "outputId": "0a362e76-50bd-4c1b-d811-61f1e7b2d220"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+-----+\n",
            "|In_or_de|count|\n",
            "+--------+-----+\n",
            "|       1| 4042|\n",
            "|       0|25958|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Take the first 30k rows\n",
        "df_subset = df.limit(30000)\n",
        "count_df_subset = df_subset.groupBy(\"In_or_de\").count()\n",
        "count_df_subset.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT8B8fKlzLmy",
        "outputId": "53c20bd5-ecbd-467b-961f-f4682e832af8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set count: 24032\n",
            "Test set count: 5968\n"
          ]
        }
      ],
      "source": [
        "# Split the data into train and test sets (80% train, 20% test)\n",
        "train_df, test_df = df_subset.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Display the number of rows in each set\n",
        "print(\"Train set count:\", train_df.count())\n",
        "print(\"Test set count:\", test_df.count())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSGbmUqNvTqc"
      },
      "source": [
        "##**Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6uWHoQR6RNH"
      },
      "source": [
        "##**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiSKDU671wiP",
        "outputId": "52aaf68b-daec-496a-8b96-c7b392efb19f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.9105120627367687\n",
            "Best Parameters:\n",
            "Number of Trees: 200\n",
            "Max Depth: 5\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler, Imputer, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import PCA\n",
        "\n",
        "# Define numerical and categorical columns\n",
        "numerical_columns = [\"Open\", \"High\", \"Low\", \"Volume\", \"YearlHigh\", \"YearlyLow\", \"WeekHigh\", \"WeekLow\", \"Day\", \"Month\", \"Year\", \"Balance\"]\n",
        "categorical_columns = [\"TickerId\"]\n",
        "\n",
        "# Define feature assembler for numerical columns\n",
        "numerical_assembler = VectorAssembler(inputCols=numerical_columns, outputCol=\"numerical_features\")\n",
        "\n",
        "# Define SimpleImputer for handling null values in numerical columns\n",
        "numerical_imputer = Imputer(strategy=\"median\", inputCols=numerical_columns, outputCols=[column + \"_imputed\" for column in numerical_columns])\n",
        "\n",
        "# Define StringIndexer for categorical columns\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\", handleInvalid=\"keep\")\n",
        "            for column in categorical_columns]\n",
        "\n",
        "# Define OneHotEncoder for categorical columns\n",
        "encoder = OneHotEncoder(inputCols=[indexer.getOutputCol() for indexer in indexers],\n",
        "                        outputCols=[column + \"_encoded\" for column in categorical_columns])\n",
        "\n",
        "# Define feature assembler to combine numerical and categorical features\n",
        "feature_assembler = VectorAssembler(inputCols=numerical_columns + [column + \"_encoded\" for column in categorical_columns], outputCol=\"features\")\n",
        "\n",
        "# Define StandardScaler for scaling features\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "\n",
        "# Define PCA for dimensionality reduction\n",
        "pca = PCA(k=5, inputCol=\"scaled_features\", outputCol=\"pca_features\")\n",
        "\n",
        "# Define Random Forest classifier\n",
        "rf = RandomForestClassifier(labelCol=\"In_or_de\", featuresCol=\"pca_features\")\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[numerical_assembler] + indexers + [encoder, feature_assembler, scaler, pca, rf])\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(rf.numTrees, [50, 100, 200])\n",
        "             .addGrid(rf.maxDepth, [5, 10, 20])\n",
        "             .build())\n",
        "\n",
        "# Define evaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"In_or_de\", metricName=\"f1\")\n",
        "\n",
        "# Define cross-validator\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3)  # Number of folds for cross-validation\n",
        "\n",
        "# Fit the model\n",
        "cv_model = crossval.fit(train_df)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "predictions = cv_model.transform(test_df)\n",
        "f1_score = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"F1 Score:\", f1_score)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters:\")\n",
        "print(\"Number of Trees:\", cv_model.bestModel.stages[-1].getNumTrees)\n",
        "print(\"Max Depth:\", cv_model.bestModel.stages[-1].getOrDefault('maxDepth'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECJd-B9I34MF"
      },
      "source": [
        "##**Logistic Regression**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gN1YrEM3KtA",
        "outputId": "45ccbe80-0f62-4f74-f8e6-bca67533b3a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.9070952293274992\n",
            "Best Parameters:\n",
            "Regularization Parameter: 0.01\n",
            "Elastic Net Parameter: 1.0\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler, Imputer, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.feature import PCA\n",
        "\n",
        "# Define PCA for dimensionality reduction\n",
        "pca = PCA(k=5, inputCol=\"scaled_features\", outputCol=\"pca_features\")\n",
        "\n",
        "# Define Logistic Regression classifier\n",
        "lr = LogisticRegression(labelCol=\"In_or_de\", featuresCol=\"pca_features\")\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[numerical_assembler] + indexers + [encoder, feature_assembler, scaler, pca, lr])\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(lr.regParam, [0.1, 0.01])\n",
        "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "             .build())\n",
        "\n",
        "# Define evaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"In_or_de\", metricName=\"f1\")\n",
        "\n",
        "# Define cross-validator\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3)  # Number of folds for cross-validation\n",
        "\n",
        "# Fit the model\n",
        "cv_model = crossval.fit(train_df)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "predictions = cv_model.transform(test_df)\n",
        "f1_score = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"F1 Score:\", f1_score)\n",
        "\n",
        "# Get the best model\n",
        "best_model_lr = cv_model.bestModel.stages[-1]\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters:\")\n",
        "print(\"Regularization Parameter:\", best_model_lr.getOrDefault('regParam'))\n",
        "print(\"Elastic Net Parameter:\", best_model_lr.getOrDefault('elasticNetParam'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EXhdsA84IVT"
      },
      "source": [
        "#**Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk1GYUN22QXW",
        "outputId": "28577f50-abfe-4199-bf7b-c96fbc82d45a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.9095280186432009\n",
            "Best Parameters:\n",
            "Max Depth: 5\n",
            "Max Bins: 16\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler, Imputer, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import PCA\n",
        "\n",
        "# Define PCA for dimensionality reduction\n",
        "pca = PCA(k=5, inputCol=\"scaled_features\", outputCol=\"pca_features\")\n",
        "\n",
        "# Define Decision Tree classifier\n",
        "dt = DecisionTreeClassifier(labelCol=\"In_or_de\", featuresCol=\"pca_features\")\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[numerical_assembler] + indexers + [encoder, feature_assembler, scaler, pca, dt])\n",
        "\n",
        "# Define parameter grid for hyperparameter tuning\n",
        "paramGrid = (ParamGridBuilder()\n",
        "             .addGrid(dt.maxDepth, [5, 10, 20])\n",
        "             .addGrid(dt.maxBins, [16, 32, 64])\n",
        "             .build())\n",
        "\n",
        "# Define evaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"In_or_de\", metricName=\"f1\")\n",
        "\n",
        "# Define cross-validator\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                          estimatorParamMaps=paramGrid,\n",
        "                          evaluator=evaluator,\n",
        "                          numFolds=3)  # Number of folds for cross-validation\n",
        "\n",
        "# Fit the model\n",
        "cv_model = crossval.fit(train_df)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "predictions = cv_model.transform(test_df)\n",
        "f1_score = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"F1 Score:\", f1_score)\n",
        "\n",
        "# Get the best model\n",
        "best_model_dt = cv_model.bestModel.stages[-1]\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters:\")\n",
        "print(\"Max Depth:\", best_model_dt.getMaxDepth())\n",
        "print(\"Max Bins:\", best_model_dt.getMaxBins())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1wKU5KC-DF9"
      },
      "source": [
        "##**Best Model(Entire Dataset)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXQ2_4OG9VgD",
        "outputId": "d0d196ce-d6ee-463d-b6d2-3f57d6e530bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train set count: 5914624\n",
            "Test set count: 1479508\n"
          ]
        }
      ],
      "source": [
        "# Split the data into train and test sets (80% train, 20% test)\n",
        "train_df, test_df = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "# Display the number of rows in each set\n",
        "print(\"Train set count:\", train_df.count())\n",
        "print(\"Test set count:\", test_df.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Logistic Regression**"
      ],
      "metadata": {
        "id": "kJCrV9wSpIGW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MXZpAo96-eWf",
        "outputId": "7e184deb-0585-472f-d81f-69509413018b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.6620702300899203\n"
          ]
        }
      ],
      "source": [
        "# Define PCA for dimensionality reduction\n",
        "pca = PCA(k=5, inputCol=\"scaled_features\", outputCol=\"pca_features\")\n",
        "\n",
        "# Define Logistic Regression classifier with the best parameters\n",
        "lr = LogisticRegression(labelCol=\"In_or_de\", featuresCol=\"pca_features\", regParam=0.01, elasticNetParam=1.0)\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[numerical_assembler] + indexers + [encoder, feature_assembler, scaler, pca, lr])\n",
        "\n",
        "# Fit the model\n",
        "model = pipeline.fit(train_df)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.transform(test_df)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"In_or_de\", metricName=\"f1\")\n",
        "f1_score = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"F1 Score:\", f1_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Random Forest**"
      ],
      "metadata": {
        "id": "tPG1dFurpNFe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KYKkUlsCHUfI",
        "outputId": "b306bbf1-4a8d-4de0-c3ad-18d405142f8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.6916681275273606\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler, Imputer, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import PCA\n",
        "\n",
        "# Define numerical and categorical columns\n",
        "numerical_columns = [\"Open\", \"High\", \"Low\", \"Volume\", \"YearlHigh\", \"YearlyLow\", \"WeekHigh\", \"WeekLow\", \"Day\", \"Month\", \"Year\", \"Balance\"]\n",
        "categorical_columns = [\"TickerId\"]\n",
        "\n",
        "# Define feature assembler for numerical columns\n",
        "numerical_assembler = VectorAssembler(inputCols=numerical_columns, outputCol=\"numerical_features\")\n",
        "\n",
        "# Define SimpleImputer for handling null values in numerical columns\n",
        "numerical_imputer = Imputer(strategy=\"median\", inputCols=numerical_columns, outputCols=[column + \"_imputed\" for column in numerical_columns])\n",
        "\n",
        "# Define StringIndexer for categorical columns\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\", handleInvalid=\"keep\")\n",
        "            for column in categorical_columns]\n",
        "\n",
        "# Define OneHotEncoder for categorical columns\n",
        "encoder = OneHotEncoder(inputCols=[indexer.getOutputCol() for indexer in indexers],\n",
        "                        outputCols=[column + \"_encoded\" for column in categorical_columns])\n",
        "\n",
        "# Define feature assembler to combine numerical and categorical features\n",
        "feature_assembler = VectorAssembler(inputCols=numerical_columns + [column + \"_encoded\" for column in categorical_columns], outputCol=\"features\")\n",
        "\n",
        "# Define StandardScaler for scaling features\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
        "\n",
        "# Define PCA for dimensionality reduction\n",
        "pca = PCA(k=5, inputCol=\"scaled_features\", outputCol=\"pca_features\")\n",
        "\n",
        "# Define Random Forest classifier\n",
        "rf = RandomForestClassifier(labelCol=\"In_or_de\", featuresCol=\"pca_features\", numTrees=200, maxDepth=5)\n",
        "\n",
        "# Define pipeline\n",
        "pipeline = Pipeline(stages=[numerical_assembler] + indexers + [encoder, feature_assembler, scaler, pca, rf])\n",
        "\n",
        "# Fit the model\n",
        "model = pipeline.fit(train_df)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.transform(test_df)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"In_or_de\", metricName=\"f1\")\n",
        "f1_score = evaluator.evaluate(predictions)\n",
        "\n",
        "print(\"F1 Score:\", f1_score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Conclusion:**\n",
        "\n",
        "We chose F-1 score as our evaluation metric as the data set is imbalanced. Initially we implemented 3 different models on a subset of the data (30,000 rows) with hyperparameters, cross validation, gridsearch and pca. The best parameters are taken for the best model and implemented on the entire dataset. We did this for Random forest and logistic regression. Here we can clearly see that random forest is clearly performing well on the unknown data."
      ],
      "metadata": {
        "id": "fNwEg36Dpa3-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}